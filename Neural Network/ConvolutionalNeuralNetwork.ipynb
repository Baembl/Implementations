{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f979b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import cifar10\n",
    "# loading the dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c8a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (50000, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape before one-hot encoding: \u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 18\u001b[0m Y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mutils(y_train, n_classes)\n\u001b[0;32m     19\u001b[0m Y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mutils(y_test, n_classes)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape after one-hot encoding: \u001b[39m\u001b[38;5;124m\"\u001b[39m, Y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:333\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'utils'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# building the input vector from the 32x32 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "Y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
    "\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# convolutional layer\n",
    "model.add(Conv2D(50, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(32, 32, 3)))\n",
    "\n",
    "# convolutional layer\n",
    "model.add(Conv2D(75, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(125, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "model.fit(X_train, Y_train, batch_size=128, epochs=50, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b29ef65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56fdc0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Predicted class: 7\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# Load your image (replace 'your_image.png' with your file path)\n",
    "img = image.load_img(r\"C:\\Users\\UAE\\Downloads\\2071882.jpeg\", target_size=(32, 32))\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Normalize the image as done for X_train/X_test\n",
    "img_array = img_array.astype('float32') / 255.0\n",
    "\n",
    "# Reshape to add batch dimension\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Run inference\n",
    "pred = model.predict(img_array)\n",
    "predicted_class = np.argmax(pred, axis=1)[0]\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be4b7be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 7 is: horse\n"
     ]
    }
   ],
   "source": [
    "cifar10_labels = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "print(\"Class 7 is:\", cifar10_labels[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3061f6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.1019 - loss: 2.3025\n",
      "Test accuracy: 0.1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "Predicted: [9 9 9 9 9 9 9 9 9 9]\n",
      "Actual:    [3 8 8 0 6 6 1 6 3 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Evaluate on test set\n",
    "loss, acc = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test accuracy: {acc:.4f}\")\n",
    "\n",
    "# Check predictions on first 10 test images\n",
    "pred_classes = np.argmax(model.predict(X_test[:10]), axis=1)\n",
    "true_classes = np.argmax(Y_test[:10], axis=1)\n",
    "print(\"Predicted:\", pred_classes)\n",
    "print(\"Actual:   \", true_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
